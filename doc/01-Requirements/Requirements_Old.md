# RAG Stream â€” **Comprehensive Requirements Specification**

*Version 0.9 â€¢ 2025-08-05*

---

## 1  Purpose & Scope

RAG Stream is a **local-first retrieval-augmented generation (RAG) workbench** that lets a power-user ingest arbitrary documents, steer retrieval weights via interactive *Attention Sliders*, optionally execute local tools (math / Python), and obtain a fully-cited answer from a remote or local LLMâ€”all inside a transparent Streamlit UI.

---

## 2  Stakeholders

| Role                     | Interest                                                                 |
| ------------------------ | ------------------------------------------------------------------------ |
| Product owner            | End-to-end demo & daily assistant running on a laptop (no cloud infra).  |
| Prompt-/Context-Engineer | Fine-tune templates, inspect retrieved chunks, toggle tool routing.      |
| Data engineer            | Extend ingestion pipeline, add file-watcher, experiment with embeddings. |
| Future OSS users         | Fork and replace LLM or vector DB without touching GUI / controller.     |

---

## 3  System Context

```
User â”€â”€â–¶ Streamlit GUI â”€â”€â–¶ Controller
                   â–²          â”‚
                   â”‚          â”œâ”€â”€â–¶ Retriever â”€â”€â–¶ VectorStore (Chroma on-disk)
                   â”‚          â”‚
                   â”‚          â”œâ”€â”€â–¶ AttentionWeights
                   â”‚          â”‚
                   â”‚          â”œâ”€â”€â–¶ ToolDispatcher â”€â”€â–¶ {MathTool | PyTool}
                   â”‚          â”‚
                   â”‚          â”œâ”€â”€â–¶ PromptBuilder â”€â”€â–¶ LLMClient (OpenAI GPT-4o)
                   â”‚          â”‚
                   â”‚          â””â”€â”€â–¶ Logging / Paths utilities
DocumentLoader â—€â”€â”€â”€â”˜          â”‚
     â–²                         â””â”€â”€â–¶ Settings (env / .env / CLI)
     â””â”€ Chunker â”€ Embedder â”€ VectorStore.add()
```

---

## 4  Functional Requirements

### 4.1  Ingestion / Memory

| ID     | Requirement                                                                 | Priority |
| ------ | --------------------------------------------------------------------------- | -------- |
| ING-01 | Load `.pdf`, `.md`, `.txt`, `.docx` from *drag-and-drop* or watched folder. | Must     |
| ING-02 | RecursiveTextSplitter (window = 1 024 tok, overlap = 200 tok).              | Must     |
| ING-03 | Default embedding model **BGE-Large-v3** via `sentence_transformers`.       | Must     |
| ING-04 | Persist and delta-update Chroma collection on disk (`./data/chroma_db`).    | Must     |
| ING-05 | Emit ingestion log (docs added / skipped / updated).                        | Should   |

### 4.2  Retrieval & Ranking

| ID     | Requirement                                                           | Priority |
| ------ | --------------------------------------------------------------------- | -------- |
| RET-01 | Cosine top-k search (k = 20) with embedder from 4.1.                  | Must     |
| RET-02 | Multiply each document score by UI-supplied slider weight  wáµ¢âˆˆ\[0,1]. | Must     |
| RET-03 | Cross-encoder rerank with `mixedbread-ai/mxbai-rerank-xsmall-v1`.     | Must     |
| RET-04 | Expose retriever latency in the UI status bar.                        | Should   |

### 4.3  Prompt Orchestration

| ID     | Requirement                                                                       | Priority |
| ------ | --------------------------------------------------------------------------------- | -------- |
| ORC-01 | Build system prompt with slots: `{{question}}`, `{{context}}`, `{{tool_output}}`. | Must     |
| ORC-02 | Inject `<source_i>` tags for cited chunks for UI highlighting.                    | Must     |
| ORC-03 | Circular limit: prompt â‰¤ 8 k tokens incl. context & tool output.                  | Must     |

### 4.4  Tooling

| ID      | Requirement                                                              | Priority |
| ------- | ------------------------------------------------------------------------ | -------- |
| TOOL-01 | Parse `calc:` or `py:` prefixesâ€”route remainder to local tool.           | Must     |
| TOOL-02 | MathTool â†’ evaluate via `sympy.sympify`, return pretty string.           | Must     |
| TOOL-03 | PyTool â†’ run in `exec` sandbox with `asyncio` timeout = 2 s.             | Should   |
| TOOL-04 | Register new tools by subclassing `BaseTool`, auto-discover at start-up. | Should   |

### 4.5  LLM Interface

| ID     | Requirement                                                             | Priority |
| ------ | ----------------------------------------------------------------------- | -------- |
| LLM-01 | Default remote client: `gpt-4o` with temperature 0.2, max\_tokens 512.  | Must     |
| LLM-02 | Pluggable local model via `ollama run llama3:instruct`, flag `--local`. | Should   |
| LLM-03 | Stream tokens to UI with first byte < 1 s.                              | Must     |
| LLM-04 | Retry on HTTP 429/5xx with exponential back-off max 3 tries.            | Should   |

### 4.6  UI / App

| ID    | Requirement                                                         | Priority |
| ----- | ------------------------------------------------------------------- | -------- |
| UI-01 | Two-pane layout: left = prompt & sliders, right = answer & sources. | Must     |
| UI-02 | Show chunk pills with score Ã— weight Ã— rerank; click opens raw doc. | Should   |
| UI-03 | Dark & light theme auto-switch (`streamlit-theme`).                 | Could    |
| UI-04 | Download chat history as Markdown with citations.                   | Should   |

---

## 5  Non-Functional Requirements

| Category          | Target                                                              |
| ----------------- | ------------------------------------------------------------------- |
| **Latency**       | < 3 s p95 promptâ†’first token with 1 M-token Chroma store on M2-Pro. |
| **Memory**        | â‰¤ 6 GB RAM peak (embeddings loaded on demand).                      |
| **Extensibility** | Add a new tool or embedding model without touching > 1 file.        |
| **Observability** | Structured logs JSON â†’ `ragstream/utils/logging.py`.                |
| **Test coverage** | Unit 80 % (`pytest` + `hypothesis` for splitter & retriever).       |
| **Security**      | Tool sandbox runs in separate process; no network in math/py tools. |
| **Licensing**     | Apache-2.0 except external models retaining original licenses.      |

---

## 6  Technology Stack

| Layer           | Library / Service                                   | Version (Aug 2025)                |
| --------------- | --------------------------------------------------- | --------------------------------- |
| GUI             | Streamlit                                           | 1.38                              |
| Embeddings      | `bge-large-en-v3`, `E5-Mistral` (optional)          | via `sentence_transformers = 3.0` |
| Vector DB       | Chroma                                              | 0.10                              |
| Cross-encoder   | `mixedbread-ai/mxbai-rerank-xsmall-v1`              | ðŸ¤— `cross-encoder = 0.6`          |
| LLM API         | OpenAI (`openai>=1.15.0`)                           | GPT-4o                            |
| Local LLM (opt) | Ollama                                              | 0.2                               |
| Math            | SymPy                                               | 1.13                              |
| Testing         | pytest, coverage, hypothesis                        | latest                            |
| Packaging       | Poetry / PEP 621 (`pyproject.toml`)                 | 1.8                               |
| CI              | GitHub Actions (`python-versions {3.10,3.11,3.12}`) | -                                 |

---

## 7  Directory / Module Tree

```
.
â”œâ”€â”€ .gitignore
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ chroma_db/
â”‚   â””â”€â”€ doc_raw/
â”œâ”€â”€ ragstream/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ controller.py
â”‚   â”‚   â””â”€â”€ ui_streamlit.py
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ settings.py
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ loader.py            # DocumentLoader
â”‚   â”‚   â”œâ”€â”€ chunker.py           # Chunker
â”‚   â”‚   â”œâ”€â”€ embedder.py          # Embedder
â”‚   â”‚   â””â”€â”€ vector_store.py      # VectorStore
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ attention.py         # AttentionWeights
â”‚   â”‚   â”œâ”€â”€ reranker.py          # Reranker
â”‚   â”‚   â””â”€â”€ retriever.py         # Retriever
â”‚   â”œâ”€â”€ orchestration/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ prompt_builder.py    # PromptBuilder
â”‚   â”‚   â””â”€â”€ llm_client.py        # LLMClient
â”‚   â”œâ”€â”€ tooling/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_tool.py         # BaseTool
â”‚   â”‚   â”œâ”€â”€ math_tool.py         # MathTool
â”‚   â”‚   â”œâ”€â”€ py_tool.py           # PyTool
â”‚   â”‚   â”œâ”€â”€ registry.py          # ToolRegistry
â”‚   â”‚   â””â”€â”€ dispatcher.py        # ToolDispatcher
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logging.py
â”‚       â””â”€â”€ paths.py
â””â”€â”€ pyproject.toml  (or requirements.txt)
```

---

## 8  Open Issues / Risks

| Risk                                                              | Mitigation                                                   |
| ----------------------------------------------------------------- | ------------------------------------------------------------ |
| Cross-encoder latency on CPU.                                     | Cache top-32 chunks, run cross-encoder only once.            |
| SymPy sandbox leakage via `eval`.                                 | Use `sympy.parsing.sympy_parser` + restricted globals.       |
| Streamlit session state resets when file watcher triggers reload. | Debounce file-watch events; persist state to JSON.           |
| Embedding model size â‰ˆ 2 GB > memory on low-spec laptops.         | Offer `bge-base-v1` fallback; lazy-load model on first call. |

---

## 9  Acceptance Criteria (5-day MVP)

1. Ingest at least **1 000** Markdown pages; run dense + rerank retrieval; answer in â‰¤ 5 s p95.
2. Attention slider demonstrably changes ranking order live.
3. `calc: 3*(4+5)` prompt returns `27` inline.
4. Streamlit UI shows citations and chunk pop-ups.
5. All unit tests pass; `pytest` reports â‰¥ 80 % coverage.

---

## 10  Glossary

| Term                 | Meaning                                                       |
| -------------------- | ------------------------------------------------------------- |
| **RAG**              | Retrieval-Augmented Generation.                               |
| **Attention Slider** | UI widget assigning manual weights to per-document groups.    |
| **ToolDispatcher**   | Router that detects and executes local tools before LLM call. |
| **Chunk**            | Fixed-size text window (â‰ˆ 500 tokens) stored with embedding.  |

---

> **Status:** Spec validated against current repo layout (commit *HEAD* on 2025-08-05). Any structural change should update sections 4 & 7 and increment spec version.
